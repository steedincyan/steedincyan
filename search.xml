<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java多线程笔记]]></title>
    <url>%2F2017%2F10%2F03%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[调试线程化的程序线程问题主要来自四个方面： 死锁 活锁当一个线程忙于接受新任务以致它永远没有机会完成任何任务时 内存损坏。使用 synchronized 关键字，则完全可以避免内存错误 资源耗尽。如果线程数相当大，或者某个资源的侯选线程数远远超过了可用的资源数，则最好使用 资源池。 优先级不可靠。使用yield（）来降低优先级更可靠。 线程协作机制协作式线程 程序开发员可以精确地决定某个线程何时会被其他线程挂起，允许它们与对方有效地合作。 缺点在于某些恶意或是写得不好的线程会消耗所有可获得的 CPU 时间，导致其他线程“饥饿”。 在协作式模型中，是否能保证线程正常放弃处理器，不掠夺其他线程的执行时间，则完全取决于程序员。 调用 yield() 方法能够将当前的线程从处理器中移出到准备就绪队列中。如果线程正拥有一个锁，则当它调用 yield() 时不能够释放这个锁。这就意味着即使这个线程已经被挂起，等待这个锁释放的其他线程依然不能继续运行。为了缓解这个问题，最好不在同步方法中调用 yield 方法。 另一个方法则是调用 sleep() 方法，使线程放弃处理器，并且在 sleep 方法中指定的时间间隔内睡眠。 另外一个解决方法则是调用 wait() 方法，使处理器放弃它当前拥有的对象的锁。如果对象在方法级别上使同步的，这种方法能够很好的工作。因为它仅仅使用了一个锁。如果它使用 fine-grained 锁，则 wait() 将无法放弃这些锁。此外，一个因为调用 wait() 方法而阻塞的线程，只有当其他线程调用 notifyAll() 时才会被唤醒。 抢占式线程操作系统可以在任何时候打断线程。 JVM 规范并没有特别规定线程模型，Java 开发员必须编写可在两种模型上正确运行的程序。 补充： Java 多线程支持在版本 1.1 和版本 1.2 中做了重大修订，stop()、suspend() 和 resume() 函数已不提倡使用。 必须确保不在同步代码中包含那些阻塞（如IO）调用，或确认在一个用同步阻塞代码的对象中存在非同步方法来取消阻塞调用。 原子操作代码块中的代码段一旦开始执行，就要在该线程被换出处理器之前执行完毕。在 Java 编程中，分配一个小于 32 位的变量空间是一种原子操作，而此外象 double 和 long 这两个 64 位数据类型的分配就不是原子的。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coursera Spark学习笔记]]></title>
    <url>%2F2017%2F09%2F12%2FCourseraSpark%2F</url>
    <content type="text"><![CDATA[Spark 笔记Features over Hadoop latency通过减少disk操作来提升计算效率 fault tolerance只保存数据和函数过程，不保存中间结果 Transform and Action Transform is lazyRDD的map等操作是lazy的 Action is eagerRDD的reduce等操作是eager(立即求值)的 在求值之前，Spark会分析和优化操作链。 对RDD进行求值的时候，每次对10个元素求值，保存结果，然后继续对剩下的元素求值。 Cache and Persistence RDDs are computed each time you run a ACTION on thempoints 被计算了i次points将不再被重复计算 cache可用的参数： Cluster Manager 主程序不直接执行函数，函数和数据被分发到集群节点 Pair RDD Shuffle and Partition groupByKey产生的每个键值对只能存在于单个node上，不能跨node。默认触发hash分区。 分区后的数据通常要persist，不然每次对分区数据的引用，都会触发分区操作range分区： *只有以下操作可以保持分区，其他会清除分区记忆： 其他操作如map，可以直接改变pair RDD的key，导致原有分区失去意义： Dependencies 一个父RDD被多个子RDD依赖 == wide dependency 依赖的类型：分析依赖的类型： 使用dependencies方法2.使用toDebugString方法 Data FrameCatalystCatalyst是Spark SQL的optimizer，通过以下原理优化Spark SQL操作： 首先需要假定Catalyst满足：1.知晓所有数据类型2.知道数据schema，即数据组织方式3.知晓将对数据进行的操作的细节 优化目标主要有：1.对SQL操作的顺序重新排列2.不去读取与操作无关的数据3.避免不必要的partition操作 TungstenTungsten为Spark优化数据存储和垃圾回收：1.data encoder通过分析表信息，将数据序列化后打包放进内存，节省空间。2.base on column大多数操作更多的是读写某个列的值，将数据按分列存储，可以加速排序、分组等操作。3.off—heap由Tungsten接管堆，避免JVM过度暂停和收集垃圾。 Data Frame的缺点1.SQL操作错误无法在Compile期间检测：12//如果state列不存在，只能得到runtime报错listingDF.filter($&quot;state&quot;==&quot;CA&quot;) 2.存储的数据结构太复杂的话，Tungsten encoder无法为其优化3.非结构化的数据，没法使用Date Frame存储，只能回到RDD 适用范围 additions]]></content>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
</search>
