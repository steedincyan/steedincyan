<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[.profile, .bash_profile, .bashrc 的区别]]></title>
    <url>%2F2018%2F02%2F27%2Fprofile-bash-profile-bashrc-%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[profile, bash_profile和bashrc 的区别 通过命令行登录系统时，login shell读取.profile。 特别的，BASH的login shell优先读取.bash_profile，找不到.bash_profile时才读取.profile。 通过输入命令(如bash命令)而非登录方式启动shell时()，读取.bashrc ~/.profile is the place to put stuff that applies to your whole session, such as programs that you want to start when you log in (but not graphical programs, they go into a different file), and environment variable definitions. ~/.bashrc is the place to put stuff that applies only to bash itself, such as alias and function definitions, shell options, and prompt settings. (You could also put key bindings there, but for bash they normally go into ~/.inputrc)]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程间通信(IPC)]]></title>
    <url>%2F2018%2F01%2F08%2F%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1(IPC)%2F</url>
    <content type="text"><![CDATA[各种通信方式的比较和优缺点 管道：速度慢，容量有限，只有父子进程能通讯 FIFO：任何进程间都能通讯，但速度慢 消息队列：容w量受到系统限制，且要注意第一次读的时候，要考虑上一次没有读完数据的问题 信号/信号量：不能传递复杂消息，只能用来同步 共享内存区：能够很容易控制容量，速度快，但要保持同步，比如一个进程在写的时候，另一个进程要注意读写的问题，相当于线程中的线程安全，当然，共享内存区同样可以用作线程间通讯，不过没这个必要，线程间本来就已经共享了同一进程内的一块内存]]></content>
      <tags>
        <tag>操作系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[死锁、活锁和饥饿]]></title>
    <url>%2F2018%2F01%2F04%2F%E6%AD%BB%E9%94%81%E3%80%81%E6%B4%BB%E9%94%81%E5%92%8C%E9%A5%A5%E9%A5%BF%2F</url>
    <content type="text"><![CDATA[死锁两个/两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。死锁发生的条件： 互斥条件：线程对资源的访问是排他性的，如果一个线程对占用了某资源，那么其他线程必须处于等待状态，直到资源被释放。 请求和保持条件：线程T1至少已经保持了一个资源R1占用,但又提出对另一个资源R2请求，而此时，资源R2被其他线程T2占用，于是该线程T1也必须等待，但又对自己保持的资源R1不释放。 不剥夺条件：线程已获得的资源，在未使用完之前，不能被其他线程剥夺，只能在使用完以后由自己释放。 环路等待条件：在死锁发生时，必然存在一个“进程-资源环形链”，即：{p0,p1,p2,…pn},进程p0（或线程）等待p1占用的资源，p1等待p2占用的资源，pn等待p0占用的资源。（最直观的理解是，p0等待p1占用的资源，而p1而在等待p0占用的资源，于是两个进程就相互等待）活锁(双方都太礼貌)线程1可以使用资源，但它很礼貌，让其他线程先使用资源，线程2也可以使用资源，但它很绅士，也让其他线程先使用资源。这样你让我，我让你，最后两个线程都无法使用资源。饥饿(被系统遗忘在角落)是指如果线程T1占用资源R，线程T2先请求封锁R，T3后请求资源R，当T1释放了R上的封锁后，系统首先批准了T3的请求，T2仍然等待。然后T4又请求封锁R，当T3释放了R上的封锁之后，系统又批准了T4的请求……，T2可能永远等待。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coursera Spark学习笔记]]></title>
    <url>%2F2017%2F09%2F12%2FCourseraSpark%2F</url>
    <content type="text"><![CDATA[Features over Hadoop latency通过减少disk操作来提升计算效率 fault tolerance只保存数据和函数过程，不保存中间结果 Transform and Action Transform is lazyRDD的map等操作是lazy的 Action is eagerRDD的reduce等操作是eager(立即求值)的 在求值之前，Spark会分析和优化操作链。 对RDD进行求值的时候，每次对10个元素求值，保存结果，然后继续对剩下的元素求值。 Cache and Persistence RDDs are computed each time you run a ACTION on thempoints 被计算了i次points将不再被重复计算 cache可用的参数： Cluster Manager 主程序不直接执行函数，函数和数据被分发到集群节点 Pair RDD Shuffle and Partition groupByKey产生的每个键值对只能存在于单个node上，不能跨node。默认触发hash分区。 分区后的数据通常要persist，不然每次对分区数据的引用，都会触发分区操作range分区： *只有以下操作可以保持分区，其他会清除分区记忆： 其他操作如map，可以直接改变pair RDD的key，导致原有分区失去意义： Dependencies 一个父RDD被多个子RDD依赖 == wide dependency 依赖的类型：分析依赖的类型： 使用dependencies方法2.使用toDebugString方法 Data FrameCatalystCatalyst是Spark SQL的optimizer，通过以下原理优化Spark SQL操作： 首先需要假定Catalyst满足：1.知晓所有数据类型2.知道数据schema，即数据组织方式3.知晓将对数据进行的操作的细节 优化目标主要有：1.对SQL操作的顺序重新排列2.不去读取与操作无关的数据3.避免不必要的partition操作 TungstenTungsten为Spark优化数据存储和垃圾回收：1.data encoder通过分析表信息，将数据序列化后打包放进内存，节省空间。2.base on column大多数操作更多的是读写某个列的值，将数据按分列存储，可以加速排序、分组等操作。3.off—heap由Tungsten接管堆，避免JVM过度暂停和收集垃圾。 Data Frame的缺点1.SQL操作错误无法在Compile期间检测：12//如果state列不存在，只能得到runtime报错listingDF.filter($&quot;state&quot;==&quot;CA&quot;) 2.存储的数据结构太复杂的话，Tungsten encoder无法为其优化3.非结构化的数据，没法使用Date Frame存储，只能回到RDD 适用范围 additions]]></content>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM(笔记)]]></title>
    <url>%2F2017%2F05%2F20%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM(%E7%AC%94%E8%AE%B0)%2F</url>
    <content type="text"><![CDATA[内存区域与内存溢出异常运行时数据区域1. 程序计数器即线程的下一条指令的指示器 是线程私有的：每条线程都有一个独立的程序计数器，独立存储。 如果执行Native方法，计数器为空 不抛出OutOfMemoryError 2. Java虚拟机栈描述的是方法的内存模型：方法执行时创建一个栈帧。 存储局部变量表，操作数栈，动态链接，方法出口等 局部变量表：存放了8种基本类型，对象引用（对象地址或句柄），返回地址等 也是线程私有的 生命周期与线程相同 线程申请栈大于虚拟机允许：抛出StackOverFlowError；动态扩展大于系统允许：抛出OutOfMemoryError；申请新线程允许：抛出OutOfMemoryError； 3. 本地方法栈为Native方法调用服务，实现方式非常自由。 也是线程私有的 抛出的异常同上 4. Java堆原则上所有对象实例，数组和静态域都在此分配。由于JIT编译器与逃逸分析技术， 栈上分配 与 标量替换 会破坏这个原则。 是线程共享的 抛出OutOfMemoryError 5. 方法区存储 已被虚拟机加载 的类信息、常量池、静态变量、即时编译器编译的代码等 是线程共享的 不等价于“永久代”。过去HotSpot用“永久代”实现方法区。 抛出OutOfMemoryError 运行时常量池属于方法区。存放被加载类的常量池、运行期间新的常量（String的intern()方法） 6. 直接内存不属于 运行时数据区域 ，也不属于Java虚拟机规范。 NIO使用的Channel和Buffer方式，会调用Native函数直接在操作系统中开辟内存空间。Java堆中的DirectByteBuffer对象持有此空间地址。 抛出OutOfMemoryError 虚拟机中的对象对象创建过程：初始化new一个对象时，虚拟机从方法区的常量池查找类符号，将此类加载、解析和初始化（如果是第一次）。然后分配内存，归零，执行init初始化。 对象的内存布局在HotSpot中，对象有3部分： 对象头分为两块。(a) 哈希码，GC分代年龄，状态锁标志，线程持有的锁，偏向线程ID，偏向时间戳等。(32或者64bit)(b) 类型指针/数组长度：指向对象的类数据（并非查找类的唯一方法）。 实例数据排列方式父类的基本类型，指针；子类的基本类型，指针；相同宽度的放在一起。实际上CompactFields默认开启，所以子类窄变量可以插入父类变量缝隙。 填充。实例数据是8byte的整数倍。 垃圾收集器与内存分配策略对象是否死亡可作为GC Roots的对象有： 虚拟机栈（栈帧中的本地变量表）引用的对象 方法区中类的静态属性引用的对象 方法区中常量引用的对象 本地方法栈中JNI（Native方法）引用的对象 引用类型 强引用，永不回收如“Object o = new Object()“ 软引用。内存不够时，系统回收其他对象；如果还是不够，就开始回收软引用。用SoftReference类实现 弱引用。撑不过任何一次垃圾回收。用WeakReference实现 虚引用。除了在垃圾回收时收到一个通知，没有任何作用。用PhantomReference实现 finalize()方法实现了finalize()的对象，会被移入F-Queue（只会被移入一次），被Finalizer线程执行，不保证完整成功。finalize()通过使其他变量引用自己，可以将自己从队列中拯救。但是再也没有进入F-Queue的机会了。finalize()是个傻到爆炸的设计，不能保证任何功能的实现。不允许使用这货。 方法区的回收主要回收两部分内容 常量。没有用被其他对象引用/使用的常量如“abc”。 类。满足以下条件，仅仅是可以回收，而不是必然被回收。(a) 所有实例被回收，即堆中无实例(b) 加载该类的ClassLoader已被回收(c) 对应的java.lang.Class对象没有被引用 HostSpot寻找垃圾-可达性分析 枚举根节点类加载完成后，HotSpot根据对象实例中引用的偏移量、编译过程中栈和寄存器中引用的位置，直接建立引用链（OopMap数据结构）。 安全点(a) 程序“长时间执行”点，如方法调用、循环跳转、异常跳转(b) 创建对象/需要分配内存 的地方线程主动轮询GC设置的安全点标志，并在安全点停车，为GC建立引用链提供同步条件。 安全区域在一段代码中，若引用关系不会变化，它就是安全区域。处于sleep和blocked的线程不响应GC，没法识别/进入安全点。线程进入安全区域后，标识自己进入安全区。GC启动时，就不用管这些线程。 垃圾收集器 Serial（单线程，新生代）停顿长，适合 客户端 。 ParNew（多线程，新生代）适合 服务端 。 Parallel Scavenge类似ParNew，但是专注垃圾收集的吞吐率，停顿更长。不适合交互任务。可以开启自适应调节策略，省心。 Serial Old（单线程，老年代）搭配图： Parallel Old（多线程，老年代）同样专注垃圾收集的吞吐率搭配图： CMS过程:(1)初始标记。短暂停顿，记录GC Roots能直接关联到的对象。(2)并发标记。长时间并发，追踪GC Roots的下层节点。(3)重新标记。短暂停顿，修正上一步过程中变动的记录。(4)并发清除。长时间并发，清除垃圾。缺点:(1)占用CPU资源多(2)并发清除阶段产生新的对象，叫做“浮动垃圾”，占用老年区空间。空间不够则触发”Concurrent Mode Failure“，可以用Serial Old作为备案。(3)标记-清除产生利用碎片空间。但是开启某选项可以触发整理。 G1 并行+并发，分代收集，空间整理。 可预测的停顿：允许指定单位时长的停顿百分比，通过建立时间模型实现。 将Java堆分成多个等大小Region，跟踪各个Region，分析回收性价比。 内存分配与回收策略 对象在新生代Eden中分配。空间不够时触发Minor GC，回收新生代。依然不够，旧对象转移到Old。Minor GC: 新生代 中的GC。Major GC/ Full GC: Old中的GC，通常伴随Minor GC。速度比Minor GC慢10倍以上。 大对象（ 长字符串、数组）容易触发GC，且MInor GC复制大对象耗时。可以开启选项使大对象直接进入Old 长时间存活的对象进入Old，计算对象Survive次数实现。 Survivor中一半对象年纪相同，则大于此年纪的直接进入Old Old中的最大连续空间能容纳历次GC中从Survior晋升到Old的对象平均值，则冒险Minor GC，而不进行Full GC。冒险失败再Full GC。总之尽量避免Full GC。 虚拟机工具 jps。java 进程状态查询（类名，路径，参数等）。jps -lv jstat。虚拟机信息监视。jstat -gcutil port interval(ms) times jinfo。查看调整虚拟机参数。 jmap。生成堆转出快照。 jhat。快照分析工具，太粗糙，基本不用。 可视化工具jdk自带的jconsole，线程，内存，cpu全方位检测，甚至可以分析死锁 VisualVM，功能更多，插件也多 类加载机制有且只有5种情况要求必须对类进行“初始化”(加载、验证、准备自然需要在此之前开始)： 遇到new, getstatic, putstatic, 或 invokestatic 这四条字节码时。常见场景是： new 关键字实例化对象 读取/或者设置一个类的静态字段 调用一个类的静态方法 使用java.lang.reflect包进行反射调用 初始化一个类前先初始化其父类；没有引用父接口资源，可以直接初始化一个接口 虚拟机启动时先初始化包含 main() 方法的类 MethodHandle 实例解析结果与「1.」对应 类加载过程1. 加载获取类的二进制流 ==(通过文件格式验证)==&gt; 结构化存入方法区 ==&gt; 生成这个类的 java.lang.Class对象，作为类数据的入口 创建数组时，会将数组标记在类加载器上(基本类型：Bootstrap ClassLoaer，引用类型：对应的类加载器) 2.验证-Xverify:none可以用来关闭大部分验证过程 文件格式验证(Class 文件格式)魔数，主次版本，常量池规范……检测完就存入方法区。 元数据验证(语义分析)有无父类，实现了接口的方法，字段、方法命名矛盾…… 字节码验证(控制流、数据流分析)指令不可以乱跳，数据不可以随意操作。因为『Halting Problem』，JDK 1.7后不再推导数据流的合法性，而是使用类型检查(检查StackMapTable属性合法) 符号引用验证(『解析』阶段发生)符号引用的内容是否存在，是否有权限访问…… 3. 准备在方法区内，给类变量(static 变量)分配内存、赋零值，给 static final 变量赋初值 4. 解析即将符号引用解析为直接引用(指针、偏移量、句柄) 除了invokedynamic指令，虚拟机只解析一次符号引用，并将其缓存 类/接口解析 在当前代码中将符号引用解析C 类/接口：符号引用==(虚拟机查找)==&gt;C 的全限定名==(虚拟机交给)==&gt;当前类的加载器==(加载 C)==&gt; 如果 C 是引用数组，按上述过程解析引用的类，再生成数组对象 字段解析 通过 CONSTANT_Class_info 找到字段所属类/接口C==&gt;找 C 中的匹配==&gt;继续找 C 的接口和父接口的匹配=&gt;找 C的父类树。找到为止。 多个匹配同时存在于C 和 C 的接口树中，编译会失败 类方法解析同样的方法找到 C 的符号引用==&gt;C 是接口，抛出异常==&gt;找 C 中的匹配==&gt;找 C 父类树种的匹配==&gt;找接口树中的匹配，找到就抛异常。找到为止。 接口方法解析C 是类，抛异常==&gt;找 C 中的匹配==&gt;找 C 的父接口树。找到为止。 5. 初始化即执行类构造器()方法的过程。 编译器按顺序搜集 static 变量赋值动作、static 块，组成()。没有则不生成()。 ()执行不会触发父类()，虚拟机保证已经执行了父类()。意味着父类的静态语句执行顺序优先于子类。 ()只会被一个线程占有，且只执行一次。 类加载器 被不同类加载器加载的类，必定不相等 所有加载器继承自 java.lang.ClassLoader 双亲委派模型 Bootstrap ClassLoader 加载/lib 的类(虚拟机只认几个名字) Extension ClassLoader加载_lib_ext 的类 Application 加载用户路径 ClassPath 的类 双亲委派模型保证了Object 类在各个加载器环境中都相等双亲委派模型的破坏： loadClass()方法里是双亲委派逻辑，不应更改。重写findClass()方法来加载自己的类。 JNDI 通过 java.lang.Thread 的 setContextLoader()实现父加载器调用子加载器。 OSGi 的加载器是网状结构。 早期(编译器)优化编译器种类 前端编译器(.java==&gt;.class)：如Javac JIT 编译器(.class==&gt;01)：HotSpot VM 的 C1、C2编译器 AOT编译器(.java==&gt;01) Javac 编译过程 解析与填充符号表 词法分析： .class ==&gt; Token。”int a=b+2” 解析为6个不可再分的 Token：int, a, =, b, +, 2 语法分析：Token==&gt;语法树(包、类型、修饰符、接口……)。 填充符号表 插入式注解处理器的注解处理过程注解可以增删改语法树中的任意元素。修改后返回填充符号表步骤。 语义分析与字节码生成 标注检查。常量折叠： int a = 1 + 2 ==&gt; int a = 3 数据、控制流分析。修饰的局部变量的final，在.class中消失 解语法糖 字节码生成 语法糖 泛型与类型擦除Java 中的泛型只在.java中存在，在.class中被替换成 Raw Type + 强制转型。Map() ==&gt; Map()但是下面的可以编译成功，因为.class中的方法签名涉及到返回值 自动拆箱、装箱 for( int i : list){} ==&gt; (1) Integer 包装 i；(2) .class中的迭代器 IntegerA == IntegerB / intA，；只有遇到算数才自动拆箱。 条件编译根据if 判断中的常量，修剪条件分支 代码质量检查工具：CheckStyle, FindBugs, Klocwork]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发编程的艺术(笔记)]]></title>
    <url>%2F2017%2F02%2F28%2FJava%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E7%9A%84%E8%89%BA%E6%9C%AF(%E7%AC%94%E8%AE%B0)%2F</url>
    <content type="text"><![CDATA[并发编程的挑战减少上下文切换： 无锁并发编程 CAS(如Atomic类型) 使用最少线程 协程 避免死锁： 避免一个线程获取多个锁 避免一个锁内占用多个资源 尝试使用定时锁，lock.tryLock(timeout)代替内部锁机制 Java并发机制的底层实现原理volitilevolatile是轻量级的synchronized，合理使用的话成本更低，因为没有线程上下文的切换和调度。volatile变量的赋值语句，会触发CPU指令集的lock，lock指令在多核处理器中做两件事： 将当前处理器缓存行的数据写回到内存 这个写回内存的操作会使其他CPU核缓存了该内存地址的数据失效 synchronizedJava中的每个对象都可以作为锁： synchronized方法，锁是当前对象 静态synchronized方法，锁是当前类的Class对象 synchronized(object){}代码块，锁是括号里的对象[[偏向锁、轻量级锁和重量级锁]] 原子操作较新的处理器自动保证单处理器对一个缓存行里16/32/64位的操作是原子的，对于更复杂内存操作，处理器提供总线锁定和缓存锁定两个极致保证其原子性 总线锁定：一个处理器在总线上声明LOCK#信号，其他处理器的请求被阻塞，该处理器可以独共享内存。锁住了其他CPU和内存的通信，开销大。 缓存锁定：CPU1修改缓存行C时使用了缓存锁定，CPU2就不能同时缓存行C。 操作的数据不能缓存在CPU中，数据跨多个缓存行，或者CPU不支持缓存锁定时，只能调用总线锁定。 12345678//CAS自旋(循环)的形式如下for(;;)&#123; inti = atomicI.get(); boolean suc = atomicI.compareAndSet(i, ++i); if (suc) &#123; break; &#125;&#125; 存在的问题： 使用AtomicStampedReference解决ABA问题 CAS通常需要在一个循环中进行(自旋)，时间长开销大 可以将多个变量放在一个AtomicReference中，解决只能保证一个共享变量的原子操作的问题。 在三种锁[[偏向锁、轻量级锁和重量级锁]]中，轻量级锁和重量级锁都是用了CAS自旋方式获取锁/释放锁 Java内存模型Java并发通信机制： 这两个步骤实质上是线程A向线程B发送消息，而这个消息必须经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，为Java程序员提供内存可见性保证。 顺序一致性内存模型中，所有未同步程序的内部顺序对其他线程同样可见：而在JMM内存模型中，未同步程序不但执行顺序是无序的，而且其他线程看到的操作顺序也不一致。 volatile底层原理volatile的内存语义：当读一个volatile变量时，JMM会把该线程对应的本地内存设为无效，该线程将从主内存读取共享变量。线程A在写这个volatile变量之前所有可见的共享变量将立即变得对线程B可见。线程A写一个volatile变量，随后线程B读这个volatile变量，这个过程实质上是线程A通过主内存向线程B发送消息。 volatile重排序规则表： volatile写之前的操作，不能重排序到volatile写之后 volatile读之后的操作，不能重排序到volatile读之前 第一个操作是volatile写，第二个操作是volatile读，二者不能重排序 volatile的实现原理：通过在指令序列之间加入内存屏障(LoadStore,LoadLoad等4个屏障)，以阻止处理器重排序volatile的意义：在旧的(JSR-133之前)JMM中volatile操作不影响普通变量的重排序。JSR-133之前之后，volatile的读-写具有了锁的获取-释放内存语义。volatile提供了一种比锁更轻量的内存之间通信的机制。 锁的底层原理锁的内存语义：当线程获取锁时 ， JMM会把该线程对应的本地内存置为无效 。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量 。*线程A释放锁，随后线程B获取这个锁，这个过程实质上是线程A通过主内存向线程B发送消息。 锁实现都依赖于volatile的内存语义(同时也依赖CAS)： 公平锁和非公平锁释放时，最后都要写一个volatile变量state 公平锁获取时，首先会去读volatile变量 非公平锁获取时，首先用CAS更新volatile变量，这个操作同时具有volatile读和写的内存语义 concurrent包的实现通过分析volatile和锁的原理，可知Java线程通信有了4种方式： A线程写volatile_CAS更新变量，随后线程B读_CAS更新这个volatile变量。 如果我们仔细分析concurrent包的源代码实现，会发现一个通用化的实现模式。 首先，声明共享变量为volatile。 然后，使用CAS的原子条件更新来实现线程之间的同步 同时，配合以volatile的读/写和CAS所具有的volatile读和写的内存语义来实现线程之间的通信。 AQS，非阻塞数据结构和原子变量类（java.util.concurrent.atomic包中的类），这些concurrent包中的基础类都是使用这种模式来实现的，而concurrent包中的高层类又是依赖于这些基础类来实现的。 final域额重排序规则在旧的Java内存模型中，一个最严重的缺陷就是线程可能看到final域的值会改变。比如，一个线程当前看到一个整型final域的值为0（还未初始化之前的默认值），过一段时间之后这个线程再去读这个final域的值时，却发现值变为1（被某个线程初始化之后的值）。最常见的例子就是在旧的Java内存模型中，String的值可能会改变。为了修补这个漏洞，JSR133专家组增强了final的语义。通过为final域增加写和读重排序规则(通过增加内存屏障实现)，可以为Java程序员提供初始化安全保证：只要对象是正确构造的（被构造对象的引用在构造函数中没有“逸出”），那么不需要使用同步（指lock和volatile的使用）就可以保证任意线程都能看到这个final域在构造函数中被初始化之后的值。 普通变量没有这个保证。如下图所示，普通变量i的赋值操作被重排序到了构造函数之外。 happens-before规则1）程序顺序规则：一个线程中的每个操作，happens before于该线程中的任意后续操作。2）监视器锁规则：对一个锁的解锁，happen sbefore于随后对这个锁的加锁。3）volatile变量规则：对一个volatile域的写，happens before于任意后续对这个volatile域的读。4）传递性：如果A happens before B，且B happens beforeC，那么A happens before C。5）start()规则：如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens before于线程B中的任意操作。6）join()规则：如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens before于线程A从ThreadB.join()操作成功返回。 线程安全的延迟初始化延迟初始化有两种方案 双重检测的例子：1234567891011121314public class DoubleCheckedLocking &#123; private static Instance instance; public static Instance getInstance() &#123; if (instance == null) &#123; //这里instance可能正在被其他线程初始化 synchronized (DoubleCheckedLocking.class) &#123; if (instance == null) &#123; //第二次检测是否为null instance = new Instance(); return instance; &#125; &#125; &#125; return instance; &#125;&#125; 对象初始化的伪代码：123memory=allocate(); //1：分配对象的内存空间ctorInstance(memory); //2：初始化对象instance=memory; //3：设置instance指向刚分配的内存地址 其中2和3可以被重排序，导致其他线程看到半初始化的对象。这是双重检测的弊病。 使用volitile关键字改进：1private static volitile Instance instance; //加上volitile就可以保证看到的instance要么是未初始化的，要么是完全初始化的 基于类初始化12345678public class InstatnceFactory&#123; private static class InstatnceHolder &#123; public static Instance instance = new Instance(); &#125; public Instance getInstance()&#123; return InstatnceHolder.instance(); &#125;&#125; 下列情形触发类初始化： 类的实例被创建 类的静态方法被调用 类的静态字段被赋值 类的静态字段(非final)被读取 线程A触发类的初始化时，会获取一个与类初始化相关的锁。其他的线程将在锁上等待。线程A初始化完毕后，通知所有等待线程。 总结：基于类初始化的延迟加载，只能初始化静态字段。基于volitile的延迟加载，可以初始化静态字段和实例字段。 并发基础 [[线程状态转移图]] 当只剩下deamon线程时，程序退出。而deamon线程中的finally块不一定执行。 许多声明抛出InterruptedException的方法（例如Thread.sleep(long millis)方法）这些方法在抛出InterruptedException之前，Java虚拟机会先将该线程的中断标识位清除，然后抛出InterruptedException，此时调用isInterrupted()方法将会返回false。 [[安全终止线程]]线程间通信 volatile和synchronized wait和notify经典范式等待方遵循如下原则:1）获取对象的锁。2）如果条件不满足，那么调用对象的wait()方法，被通知后仍要检查条件。3）条件满足则执行对应的逻辑。123456synchronized(对象)&#123; while(条件不满足)&#123; 对象.wait(); &#125; 对应的处理逻辑&#125; 通知方遵循如下原则:1）获得对象的锁。2）改变条件。3）通知所有等待在对象上的线程。对应的伪代码如下。1234synchronized(对象)&#123; 改变条件; 对象.notifyAll();&#125; 管道输入_输出流(PipedOutputStream_PipedInputReader) Thread.join()，线程终止时，会调用线程自身的notifyAll()方法，会通知所有等待在该线程对象上的线程。 通过wait和notify经典范式实现 ThreadLocal JUCCondition 在Object的监视器模型上，一个对象拥有一个同步队列和等待队列，而并发包中的Lock（更确切地说是同步器）拥有一个同步队列(等待锁)和多个等待队列(等待condition1-conditionN) 当从await()方法返回时，当前线程一定获取了Condition相关联的锁。相当于锁同步队列的首节点（获取了锁的节点）移动到Condition的等待队列中。 调用Condition的signal()方法，将会唤醒在Condition等待队列中等待时间最长的节点（首节点），在唤醒节点之前，会将节点移到锁同步队列中。ConcurrentHashMap HashEntry代表Hash表中的一个节点，除了value值没有定义final，其余的都定义为final类型,这就意味着我们删除或者增加一个节点的时候，就必须从头开始重新建立Hash链。ConcurrentLinkedQueue阻塞队列JDK7提供了7个阻塞队列，如下。 ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列。基于数组，通过参数控制是否公平访问 LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列。基于链表。 PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列。不稳定序列(同优先级元素顺序是乱的) DelayQueue：一个使用优先级队列实现的无界阻塞队列。基于PriorityQueue(基于堆)。存入的元素实现了Delay接口，元素设置的时限过后才能从队列中取出。 SynchronousQueue：一个不存储元素的阻塞队列。传球手。每个put都要等待一个take操作 LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。提供transfer和tryTransfer两种方式存放元素。tryTransfer尝试直接将元素移交到消费者，尝试失败才存入队列。 LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。双端队列，减少了一半的竞争阻塞队列实现：基于Condition的 等待/通知(awaite/signal)模式，在notEmpty和notFull两个condition上等待。队列满了之后，阻塞生产者使用notFull.await()，await()实际调用了LockSupport.part(this)。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程状态转移图]]></title>
    <url>%2F2017%2F02%2F22%2F%E7%BA%BF%E7%A8%8B%E7%8A%B6%E6%80%81%E8%BD%AC%E7%A7%BB%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[在Java中线程的状态一共被分成6种： 初始态：NEW创建一个Thread对象，但还未调用start()启动线程时，线程处于初始态。 运行态：RUNNABLE在Java中，运行态包括就绪态和运行态。 就绪态该状态下的线程已经获得执行所需的所有资源，只要CPU分配执行权就能运行。所有就绪态的线程存放在就绪队列中。 运行态获得CPU执行权，正在执行的线程。由于一个CPU同一时刻只能执行一条线程，因此每个CPU每个时刻只有一条运行态的线程。 阻塞态当一条正在执行的线程请求某一资源失败时，就会进入阻塞态。而在Java中，阻塞态专指请求锁失败时进入的状态。由一个阻塞队列存放所有阻塞态的线程。处于阻塞态的线程会不断请求资源，一旦请求成功，就会进入就绪队列，等待执行。PS：锁、IO、Socket等都资源。 等待态当前线程中调用wait、join、park函数时，当前线程就会进入等待态。也有一个等待队列存放所有等待态的线程。线程处于等待态表示它需要等待其他线程的指示才能继续运行。进入等待态的线程会释放CPU执行权，并释放资源（如：锁） 超时等待态当运行中的线程调用sleep(time)、wait、join、parkNanos、parkUntil时，就会进入该状态；它和等待态一样，并不是因为请求不到资源，而是主动进入，并且进入后需要其他线程唤醒；进入该状态后释放CPU执行权 和 占有的资源。与等待态的区别：到了超时时间后自动进入阻塞队列，开始竞争锁。 终止态线程执行结束后的状态。 注意 wait()方法会释放CPU执行权和占有的锁。 sleep(long)方法仅释放CPU使用权，锁仍然占用；线程被放入超时等待队列，与yield相比，它会使线程较长时间得不到运行。 yield()方法仅释放CPU执行权，锁仍然占用，线程会被放入就绪队列，会在短时间内再次执行。 thread.join(millis) ==&gt; 在线程结束前无限调用wait(delay)，使得main线程等待。 123while (isAlive()) &#123; wait(delay);&#125; wait和notify必须配套使用，即必须使用同一把锁调用； wait和notify必须放在一个同步块中 调用wait和notify的对象必须是他们所处同步块的锁对象。]]></content>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
</search>
